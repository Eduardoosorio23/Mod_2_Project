{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project SubmissionÂ¶\n",
    "\n",
    "Student name: Eduardo Osorio\n",
    "Student pace: part time \n",
    "Scheduled project review date/time:\n",
    "Instructor name: Yish Lim\n",
    "Blog post URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "kcc = pd.read_csv('D:\\Flation\\mod_2\\Project2\\Mod_2_Project/Mod_2 _Project/data_files/kc_cleaned.csv')\n",
    "\n",
    "continuous = ['price', 'sqft_living', 'sqft_lot']\n",
    "categoricals = ['bedrooms', 'floors', 'condition', 'waterfront', 'grade', 'zipcode', 'sale_month']\n",
    "\n",
    "kcc_cont = kcc[continuous]\n",
    "\n",
    "# log features\n",
    "log_names = [f'{column}_log' for column in kcc_cont.columns]\n",
    "\n",
    "kcc_log = np.log(kcc_cont)\n",
    "kcc_log.columns = log_names\n",
    "\n",
    "# normalize (subract mean and divide by std)\n",
    "\n",
    "def normalize(feature):\n",
    "    return (feature - feature.mean()) / feature.std()\n",
    "\n",
    "kcc_log_norm = kcc_log.apply(normalize)\n",
    "\n",
    "# one hot encode categoricals\n",
    "kcc_ohe = pd.get_dummies(kcc[categoricals], columns=['bedrooms', 'floors','condition', 'waterfront', 'zipcode', 'grade', 'sale_month'], drop_first=True)\n",
    "\n",
    "preprocessed = pd.concat([kcc_log_norm, kcc_ohe], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, # Pvals over .05 are dropped\n",
    "                       verbose=True):\n",
    " \n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval)) #Adding pvals under the threshold\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval)) #drops pvals over thershold\n",
    "        if not changed:\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessed.drop('price_log', axis=1)\n",
    "y = preprocessed['price_log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "# Using a test size of 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\anaconda3\\envs\\learn-env\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  grade_7                        with p-value 0.0\n",
      "Add  grade_6                        with p-value 0.0\n",
      "Add  grade_8                        with p-value 0.0\n",
      "Add  sqft_living_log                with p-value 0.0\n",
      "Add  zipcode_98004                  with p-value 6.91272e-156\n",
      "Add  zipcode_98023                  with p-value 2.74734e-149\n",
      "Add  grade_5                        with p-value 1.71366e-121\n",
      "Add  waterfront_1.0                 with p-value 7.09443e-122\n",
      "Add  zipcode_98042                  with p-value 5.02276e-123\n",
      "Add  zipcode_98092                  with p-value 4.38807e-114\n",
      "Add  zipcode_98112                  with p-value 1.58902e-105\n",
      "Add  zipcode_98003                  with p-value 3.84503e-103\n",
      "Add  zipcode_98038                  with p-value 9.15805e-107\n",
      "Add  zipcode_98115                  with p-value 2.51228e-95\n",
      "Add  zipcode_98117                  with p-value 2.47339e-95\n",
      "Add  zipcode_98103                  with p-value 6.42666e-105\n",
      "Add  zipcode_98105                  with p-value 3.83657e-91\n",
      "Add  grade_9                        with p-value 4.8882e-91\n",
      "Add  zipcode_98030                  with p-value 1.50386e-85\n",
      "Add  zipcode_98058                  with p-value 1.19162e-89\n",
      "Add  zipcode_98031                  with p-value 3.91183e-92\n",
      "Add  zipcode_98198                  with p-value 4.87719e-86\n",
      "Add  zipcode_98002                  with p-value 3.02104e-88\n",
      "Add  condition_3                    with p-value 4.0955e-88\n",
      "Add  zipcode_98119                  with p-value 4.79752e-85\n",
      "Add  zipcode_98168                  with p-value 3.68787e-80\n",
      "Add  zipcode_98055                  with p-value 2.93525e-84\n",
      "Add  zipcode_98022                  with p-value 2.13392e-84\n",
      "Add  zipcode_98032                  with p-value 9.21644e-86\n",
      "Add  zipcode_98039                  with p-value 4.72825e-83\n",
      "Add  zipcode_98040                  with p-value 5.39426e-79\n",
      "Add  zipcode_98199                  with p-value 5.44339e-85\n",
      "Add  zipcode_98033                  with p-value 2.14175e-85\n",
      "Add  zipcode_98107                  with p-value 3.44345e-80\n",
      "Add  zipcode_98122                  with p-value 1.12849e-75\n",
      "Add  zipcode_98116                  with p-value 9.75265e-75\n",
      "Add  zipcode_98109                  with p-value 1.02561e-78\n",
      "Add  zipcode_98178                  with p-value 2.78089e-65\n",
      "Add  zipcode_98102                  with p-value 4.65129e-63\n",
      "Add  zipcode_98188                  with p-value 1.39089e-56\n",
      "Add  sqft_lot_log                   with p-value 4.25995e-58\n",
      "Add  zipcode_98144                  with p-value 1.18279e-53\n",
      "Add  zipcode_98006                  with p-value 9.11135e-54\n",
      "Add  zipcode_98136                  with p-value 6.65103e-56\n",
      "Add  zipcode_98052                  with p-value 7.099e-51\n",
      "Add  zipcode_98008                  with p-value 4.2918e-45\n",
      "Add  zipcode_98005                  with p-value 9.7273e-41\n",
      "Add  zipcode_98177                  with p-value 1.32122e-39\n",
      "Add  zipcode_98125                  with p-value 5.4243e-34\n",
      "Add  zipcode_98126                  with p-value 3.31384e-36\n",
      "Add  zipcode_98034                  with p-value 8.32222e-38\n",
      "Add  zipcode_98053                  with p-value 2.07803e-41\n",
      "Add  zipcode_98029                  with p-value 4.28806e-45\n",
      "Add  zipcode_98074                  with p-value 1.54986e-33\n",
      "Add  zipcode_98075                  with p-value 1.01122e-39\n",
      "Add  zipcode_98007                  with p-value 3.52934e-38\n",
      "Add  zipcode_98118                  with p-value 1.93961e-38\n",
      "Add  zipcode_98027                  with p-value 7.44504e-36\n",
      "Add  zipcode_98133                  with p-value 1.57431e-32\n",
      "Add  grade_10                       with p-value 1.36594e-31\n",
      "Add  grade_4                        with p-value 1.08226e-37\n",
      "Add  sale_month_4                   with p-value 1.64272e-31\n",
      "Add  condition_5                    with p-value 1.67976e-27\n",
      "Add  condition_4                    with p-value 1.55094e-24\n",
      "Add  zipcode_98072                  with p-value 9.31474e-19\n",
      "Add  zipcode_98065                  with p-value 5.12937e-21\n",
      "Add  zipcode_98155                  with p-value 3.11878e-24\n",
      "Add  zipcode_98011                  with p-value 5.72169e-20\n",
      "Add  zipcode_98028                  with p-value 1.05914e-16\n",
      "Add  sale_month_3                   with p-value 3.86126e-16\n",
      "Add  floors_2.0                     with p-value 5.32013e-13\n",
      "Add  grade_11                       with p-value 1.37922e-12\n",
      "Add  zipcode_98077                  with p-value 1.58306e-11\n",
      "Add  zipcode_98059                  with p-value 1.32596e-10\n",
      "Add  zipcode_98106                  with p-value 1.2069e-12\n",
      "Add  zipcode_98108                  with p-value 1.59659e-10\n",
      "Add  zipcode_98056                  with p-value 7.82161e-13\n",
      "Add  zipcode_98166                  with p-value 3.67687e-12\n",
      "Add  zipcode_98045                  with p-value 6.88734e-13\n",
      "Drop zipcode_98178                  with p-value 0.0915128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\anaconda3\\envs\\learn-env\\lib\\site-packages\\ipykernel_launcher.py:33: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  zipcode_98146                  with p-value 6.86694e-16\n",
      "Drop zipcode_98038                  with p-value 0.701609\n",
      "Add  zipcode_98024                  with p-value 6.88163e-19\n",
      "Drop zipcode_98058                  with p-value 0.253674\n",
      "Add  zipcode_98019                  with p-value 1.76374e-20\n",
      "Drop zipcode_98055                  with p-value 0.760429\n",
      "Add  zipcode_98014                  with p-value 3.44994e-12\n",
      "Add  zipcode_98070                  with p-value 2.02951e-10\n",
      "Add  grade_12                       with p-value 9.26454e-07\n",
      "Add  grade_13                       with p-value 5.57858e-27\n",
      "Add  zipcode_98038                  with p-value 1.03652e-06\n",
      "Drop zipcode_98188                  with p-value 0.0611698\n",
      "Add  zipcode_98010                  with p-value 3.23464e-07\n",
      "Drop zipcode_98198                  with p-value 0.134532\n",
      "Add  zipcode_98178                  with p-value 8.484e-08\n",
      "Drop zipcode_98031                  with p-value 0.23232\n",
      "Add  zipcode_98058                  with p-value 2.16612e-11\n",
      "Drop zipcode_98022                  with p-value 0.905348\n",
      "Add  zipcode_98055                  with p-value 8.41109e-09\n",
      "Drop zipcode_98042                  with p-value 0.908718\n",
      "Add  condition_2                    with p-value 1.68024e-06\n",
      "Drop zipcode_98030                  with p-value 0.456674\n",
      "Add  floors_3.0                     with p-value 1.06526e-05\n",
      "Drop zipcode_98168                  with p-value 0.381417\n",
      "Add  bedrooms_2                     with p-value 3.82046e-05\n",
      "Add  sale_month_2                   with p-value 8.96907e-05\n",
      "Add  zipcode_98148                  with p-value 0.000227303\n",
      "Add  sale_month_5                   with p-value 0.000638836\n",
      "Add  floors_1.5                     with p-value 0.00080538\n",
      "Add  bedrooms_7                     with p-value 0.000781294\n",
      "resulting features:\n",
      "['grade_7', 'grade_6', 'grade_8', 'sqft_living_log', 'zipcode_98004', 'zipcode_98023', 'grade_5', 'waterfront_1.0', 'zipcode_98092', 'zipcode_98112', 'zipcode_98003', 'zipcode_98115', 'zipcode_98117', 'zipcode_98103', 'zipcode_98105', 'grade_9', 'zipcode_98002', 'condition_3', 'zipcode_98119', 'zipcode_98032', 'zipcode_98039', 'zipcode_98040', 'zipcode_98199', 'zipcode_98033', 'zipcode_98107', 'zipcode_98122', 'zipcode_98116', 'zipcode_98109', 'zipcode_98102', 'sqft_lot_log', 'zipcode_98144', 'zipcode_98006', 'zipcode_98136', 'zipcode_98052', 'zipcode_98008', 'zipcode_98005', 'zipcode_98177', 'zipcode_98125', 'zipcode_98126', 'zipcode_98034', 'zipcode_98053', 'zipcode_98029', 'zipcode_98074', 'zipcode_98075', 'zipcode_98007', 'zipcode_98118', 'zipcode_98027', 'zipcode_98133', 'grade_10', 'grade_4', 'sale_month_4', 'condition_5', 'condition_4', 'zipcode_98072', 'zipcode_98065', 'zipcode_98155', 'zipcode_98011', 'zipcode_98028', 'sale_month_3', 'floors_2.0', 'grade_11', 'zipcode_98077', 'zipcode_98059', 'zipcode_98106', 'zipcode_98108', 'zipcode_98056', 'zipcode_98166', 'zipcode_98045', 'zipcode_98146', 'zipcode_98024', 'zipcode_98019', 'zipcode_98014', 'zipcode_98070', 'grade_12', 'grade_13', 'zipcode_98038', 'zipcode_98010', 'zipcode_98178', 'zipcode_98058', 'zipcode_98055', 'condition_2', 'floors_3.0', 'bedrooms_2', 'sale_month_2', 'zipcode_98148', 'sale_month_5', 'floors_1.5', 'bedrooms_7']\n"
     ]
    }
   ],
   "source": [
    "result = stepwise_selection(X_train, y_train, verbose = True)\n",
    "print('resulting features:')\n",
    "print(result)\n",
    "#Feed x_train and Y_train into the stepwise function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>price_log</td>    <th>  R-squared:         </th> <td>   0.874</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.873</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1221.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 24 Oct 2020</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:15:09</td>     <th>  Log-Likelihood:    </th> <td> -5809.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 15372</td>      <th>  AIC:               </th> <td>1.179e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 15284</td>      <th>  BIC:               </th> <td>1.247e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    87</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>           <td>   -1.0974</td> <td>    0.077</td> <td>  -14.243</td> <td> 0.000</td> <td>   -1.248</td> <td>   -0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_7</th>         <td>   -0.6241</td> <td>    0.019</td> <td>  -32.516</td> <td> 0.000</td> <td>   -0.662</td> <td>   -0.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_6</th>         <td>   -0.7753</td> <td>    0.022</td> <td>  -36.028</td> <td> 0.000</td> <td>   -0.817</td> <td>   -0.733</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_8</th>         <td>   -0.4118</td> <td>    0.019</td> <td>  -21.644</td> <td> 0.000</td> <td>   -0.449</td> <td>   -0.375</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_living_log</th> <td>    0.3798</td> <td>    0.005</td> <td>   75.335</td> <td> 0.000</td> <td>    0.370</td> <td>    0.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98004</th>   <td>    2.0685</td> <td>    0.026</td> <td>   78.451</td> <td> 0.000</td> <td>    2.017</td> <td>    2.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98023</th>   <td>   -0.1396</td> <td>    0.021</td> <td>   -6.678</td> <td> 0.000</td> <td>   -0.181</td> <td>   -0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_5</th>         <td>   -0.8721</td> <td>    0.031</td> <td>  -27.717</td> <td> 0.000</td> <td>   -0.934</td> <td>   -0.810</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>waterfront_1.0</th>  <td>    1.3215</td> <td>    0.034</td> <td>   38.942</td> <td> 0.000</td> <td>    1.255</td> <td>    1.388</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98092</th>   <td>   -0.0856</td> <td>    0.025</td> <td>   -3.439</td> <td> 0.001</td> <td>   -0.134</td> <td>   -0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98112</th>   <td>    1.9487</td> <td>    0.027</td> <td>   71.177</td> <td> 0.000</td> <td>    1.895</td> <td>    2.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98003</th>   <td>   -0.0824</td> <td>    0.026</td> <td>   -3.140</td> <td> 0.002</td> <td>   -0.134</td> <td>   -0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98115</th>   <td>    1.5032</td> <td>    0.020</td> <td>   75.576</td> <td> 0.000</td> <td>    1.464</td> <td>    1.542</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98117</th>   <td>    1.4986</td> <td>    0.020</td> <td>   73.204</td> <td> 0.000</td> <td>    1.458</td> <td>    1.539</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98103</th>   <td>    1.5340</td> <td>    0.021</td> <td>   74.763</td> <td> 0.000</td> <td>    1.494</td> <td>    1.574</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98105</th>   <td>    1.7682</td> <td>    0.029</td> <td>   60.840</td> <td> 0.000</td> <td>    1.711</td> <td>    1.825</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_9</th>         <td>   -0.1283</td> <td>    0.020</td> <td>   -6.403</td> <td> 0.000</td> <td>   -0.168</td> <td>   -0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98002</th>   <td>   -0.1338</td> <td>    0.032</td> <td>   -4.153</td> <td> 0.000</td> <td>   -0.197</td> <td>   -0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition_3</th>     <td>    0.6388</td> <td>    0.082</td> <td>    7.762</td> <td> 0.000</td> <td>    0.477</td> <td>    0.800</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98119</th>   <td>    1.8648</td> <td>    0.032</td> <td>   58.121</td> <td> 0.000</td> <td>    1.802</td> <td>    1.928</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98032</th>   <td>   -0.1259</td> <td>    0.039</td> <td>   -3.262</td> <td> 0.001</td> <td>   -0.202</td> <td>   -0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98039</th>   <td>    2.4142</td> <td>    0.060</td> <td>   39.984</td> <td> 0.000</td> <td>    2.296</td> <td>    2.533</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98040</th>   <td>    1.5975</td> <td>    0.028</td> <td>   57.382</td> <td> 0.000</td> <td>    1.543</td> <td>    1.652</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98199</th>   <td>    1.6013</td> <td>    0.026</td> <td>   61.420</td> <td> 0.000</td> <td>    1.550</td> <td>    1.652</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98033</th>   <td>    1.3907</td> <td>    0.022</td> <td>   64.078</td> <td> 0.000</td> <td>    1.348</td> <td>    1.433</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98107</th>   <td>    1.6065</td> <td>    0.028</td> <td>   57.153</td> <td> 0.000</td> <td>    1.551</td> <td>    1.662</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98122</th>   <td>    1.5330</td> <td>    0.027</td> <td>   57.105</td> <td> 0.000</td> <td>    1.480</td> <td>    1.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98116</th>   <td>    1.4101</td> <td>    0.025</td> <td>   57.062</td> <td> 0.000</td> <td>    1.362</td> <td>    1.459</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98109</th>   <td>    1.8935</td> <td>    0.042</td> <td>   44.953</td> <td> 0.000</td> <td>    1.811</td> <td>    1.976</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98102</th>   <td>    1.7807</td> <td>    0.043</td> <td>   40.998</td> <td> 0.000</td> <td>    1.696</td> <td>    1.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_lot_log</th>    <td>    0.1174</td> <td>    0.004</td> <td>   28.380</td> <td> 0.000</td> <td>    0.109</td> <td>    0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98144</th>   <td>    1.2436</td> <td>    0.025</td> <td>   49.520</td> <td> 0.000</td> <td>    1.194</td> <td>    1.293</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98006</th>   <td>    1.1488</td> <td>    0.022</td> <td>   52.888</td> <td> 0.000</td> <td>    1.106</td> <td>    1.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98136</th>   <td>    1.2739</td> <td>    0.028</td> <td>   45.631</td> <td> 0.000</td> <td>    1.219</td> <td>    1.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98052</th>   <td>    1.1050</td> <td>    0.020</td> <td>   55.397</td> <td> 0.000</td> <td>    1.066</td> <td>    1.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98008</th>   <td>    1.1704</td> <td>    0.026</td> <td>   44.783</td> <td> 0.000</td> <td>    1.119</td> <td>    1.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98005</th>   <td>    1.2484</td> <td>    0.033</td> <td>   37.316</td> <td> 0.000</td> <td>    1.183</td> <td>    1.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98177</th>   <td>    1.1294</td> <td>    0.027</td> <td>   42.037</td> <td> 0.000</td> <td>    1.077</td> <td>    1.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98125</th>   <td>    1.0070</td> <td>    0.022</td> <td>   44.981</td> <td> 0.000</td> <td>    0.963</td> <td>    1.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98126</th>   <td>    1.0065</td> <td>    0.024</td> <td>   41.124</td> <td> 0.000</td> <td>    0.959</td> <td>    1.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98034</th>   <td>    0.9540</td> <td>    0.020</td> <td>   47.407</td> <td> 0.000</td> <td>    0.915</td> <td>    0.993</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98053</th>   <td>    0.9862</td> <td>    0.023</td> <td>   43.026</td> <td> 0.000</td> <td>    0.941</td> <td>    1.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98029</th>   <td>    1.0372</td> <td>    0.025</td> <td>   40.783</td> <td> 0.000</td> <td>    0.987</td> <td>    1.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98074</th>   <td>    0.9354</td> <td>    0.023</td> <td>   41.543</td> <td> 0.000</td> <td>    0.891</td> <td>    0.980</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98075</th>   <td>    0.9579</td> <td>    0.024</td> <td>   39.609</td> <td> 0.000</td> <td>    0.911</td> <td>    1.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98007</th>   <td>    1.1308</td> <td>    0.037</td> <td>   30.818</td> <td> 0.000</td> <td>    1.059</td> <td>    1.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98118</th>   <td>    0.8590</td> <td>    0.021</td> <td>   40.731</td> <td> 0.000</td> <td>    0.818</td> <td>    0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98027</th>   <td>    0.8441</td> <td>    0.023</td> <td>   37.403</td> <td> 0.000</td> <td>    0.800</td> <td>    0.888</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98133</th>   <td>    0.7843</td> <td>    0.021</td> <td>   37.110</td> <td> 0.000</td> <td>    0.743</td> <td>    0.826</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_10</th>        <td>    0.0933</td> <td>    0.022</td> <td>    4.189</td> <td> 0.000</td> <td>    0.050</td> <td>    0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_4</th>         <td>   -0.8008</td> <td>    0.083</td> <td>   -9.594</td> <td> 0.000</td> <td>   -0.964</td> <td>   -0.637</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sale_month_4</th>    <td>    0.1351</td> <td>    0.010</td> <td>   14.044</td> <td> 0.000</td> <td>    0.116</td> <td>    0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition_5</th>     <td>    0.8383</td> <td>    0.083</td> <td>   10.126</td> <td> 0.000</td> <td>    0.676</td> <td>    1.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition_4</th>     <td>    0.7101</td> <td>    0.082</td> <td>    8.623</td> <td> 0.000</td> <td>    0.549</td> <td>    0.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98072</th>   <td>    0.7635</td> <td>    0.027</td> <td>   28.193</td> <td> 0.000</td> <td>    0.710</td> <td>    0.817</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98065</th>   <td>    0.7307</td> <td>    0.026</td> <td>   28.436</td> <td> 0.000</td> <td>    0.680</td> <td>    0.781</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98155</th>   <td>    0.7101</td> <td>    0.022</td> <td>   32.622</td> <td> 0.000</td> <td>    0.667</td> <td>    0.753</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98011</th>   <td>    0.7577</td> <td>    0.031</td> <td>   24.628</td> <td> 0.000</td> <td>    0.697</td> <td>    0.818</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98028</th>   <td>    0.6795</td> <td>    0.027</td> <td>   25.159</td> <td> 0.000</td> <td>    0.627</td> <td>    0.732</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sale_month_3</th>    <td>    0.0964</td> <td>    0.010</td> <td>    9.278</td> <td> 0.000</td> <td>    0.076</td> <td>    0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>floors_2.0</th>      <td>    0.0551</td> <td>    0.008</td> <td>    6.790</td> <td> 0.000</td> <td>    0.039</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_11</th>        <td>    0.3640</td> <td>    0.027</td> <td>   13.240</td> <td> 0.000</td> <td>    0.310</td> <td>    0.418</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98077</th>   <td>    0.6496</td> <td>    0.032</td> <td>   20.396</td> <td> 0.000</td> <td>    0.587</td> <td>    0.712</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98059</th>   <td>    0.5519</td> <td>    0.022</td> <td>   25.459</td> <td> 0.000</td> <td>    0.509</td> <td>    0.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98106</th>   <td>    0.5633</td> <td>    0.025</td> <td>   22.759</td> <td> 0.000</td> <td>    0.515</td> <td>    0.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98108</th>   <td>    0.5754</td> <td>    0.033</td> <td>   17.580</td> <td> 0.000</td> <td>    0.511</td> <td>    0.640</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98056</th>   <td>    0.5073</td> <td>    0.023</td> <td>   22.460</td> <td> 0.000</td> <td>    0.463</td> <td>    0.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98166</th>   <td>    0.5114</td> <td>    0.028</td> <td>   18.419</td> <td> 0.000</td> <td>    0.457</td> <td>    0.566</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98045</th>   <td>    0.5179</td> <td>    0.030</td> <td>   17.037</td> <td> 0.000</td> <td>    0.458</td> <td>    0.577</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98146</th>   <td>    0.4475</td> <td>    0.026</td> <td>   17.111</td> <td> 0.000</td> <td>    0.396</td> <td>    0.499</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98024</th>   <td>    0.6519</td> <td>    0.047</td> <td>   13.874</td> <td> 0.000</td> <td>    0.560</td> <td>    0.744</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98019</th>   <td>    0.4818</td> <td>    0.032</td> <td>   15.201</td> <td> 0.000</td> <td>    0.420</td> <td>    0.544</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98014</th>   <td>    0.4444</td> <td>    0.039</td> <td>   11.472</td> <td> 0.000</td> <td>    0.368</td> <td>    0.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98070</th>   <td>    0.4063</td> <td>    0.041</td> <td>   10.006</td> <td> 0.000</td> <td>    0.327</td> <td>    0.486</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_12</th>        <td>    0.6555</td> <td>    0.045</td> <td>   14.463</td> <td> 0.000</td> <td>    0.567</td> <td>    0.744</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_13</th>        <td>    1.4022</td> <td>    0.134</td> <td>   10.487</td> <td> 0.000</td> <td>    1.140</td> <td>    1.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98038</th>   <td>    0.2216</td> <td>    0.020</td> <td>   11.350</td> <td> 0.000</td> <td>    0.183</td> <td>    0.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98010</th>   <td>    0.3245</td> <td>    0.043</td> <td>    7.464</td> <td> 0.000</td> <td>    0.239</td> <td>    0.410</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98178</th>   <td>    0.2248</td> <td>    0.028</td> <td>    8.037</td> <td> 0.000</td> <td>    0.170</td> <td>    0.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98058</th>   <td>    0.1855</td> <td>    0.021</td> <td>    8.675</td> <td> 0.000</td> <td>    0.144</td> <td>    0.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98055</th>   <td>    0.1632</td> <td>    0.027</td> <td>    5.967</td> <td> 0.000</td> <td>    0.110</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition_2</th>     <td>    0.4317</td> <td>    0.088</td> <td>    4.900</td> <td> 0.000</td> <td>    0.259</td> <td>    0.604</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>floors_3.0</th>      <td>   -0.0762</td> <td>    0.020</td> <td>   -3.776</td> <td> 0.000</td> <td>   -0.116</td> <td>   -0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bedrooms_2</th>      <td>    0.0449</td> <td>    0.010</td> <td>    4.481</td> <td> 0.000</td> <td>    0.025</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sale_month_2</th>    <td>    0.0525</td> <td>    0.012</td> <td>    4.240</td> <td> 0.000</td> <td>    0.028</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98148</th>   <td>    0.2068</td> <td>    0.055</td> <td>    3.731</td> <td> 0.000</td> <td>    0.098</td> <td>    0.315</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sale_month_5</th>    <td>    0.0318</td> <td>    0.009</td> <td>    3.439</td> <td> 0.001</td> <td>    0.014</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>floors_1.5</th>      <td>    0.0372</td> <td>    0.011</td> <td>    3.370</td> <td> 0.001</td> <td>    0.016</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bedrooms_7</th>      <td>   -0.2228</td> <td>    0.066</td> <td>   -3.360</td> <td> 0.001</td> <td>   -0.353</td> <td>   -0.093</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>878.545</td> <th>  Durbin-Watson:     </th> <td>   2.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3517.341</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.118</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.331</td>  <th>  Cond. No.          </th> <td>1.87e+15</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 9.02e-27. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              price_log   R-squared:                       0.874\n",
       "Model:                            OLS   Adj. R-squared:                  0.873\n",
       "Method:                 Least Squares   F-statistic:                     1221.\n",
       "Date:                Sat, 24 Oct 2020   Prob (F-statistic):               0.00\n",
       "Time:                        11:15:09   Log-Likelihood:                -5809.0\n",
       "No. Observations:               15372   AIC:                         1.179e+04\n",
       "Df Residuals:                   15284   BIC:                         1.247e+04\n",
       "Df Model:                          87                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "const              -1.0974      0.077    -14.243      0.000      -1.248      -0.946\n",
       "grade_7            -0.6241      0.019    -32.516      0.000      -0.662      -0.586\n",
       "grade_6            -0.7753      0.022    -36.028      0.000      -0.817      -0.733\n",
       "grade_8            -0.4118      0.019    -21.644      0.000      -0.449      -0.375\n",
       "sqft_living_log     0.3798      0.005     75.335      0.000       0.370       0.390\n",
       "zipcode_98004       2.0685      0.026     78.451      0.000       2.017       2.120\n",
       "zipcode_98023      -0.1396      0.021     -6.678      0.000      -0.181      -0.099\n",
       "grade_5            -0.8721      0.031    -27.717      0.000      -0.934      -0.810\n",
       "waterfront_1.0      1.3215      0.034     38.942      0.000       1.255       1.388\n",
       "zipcode_98092      -0.0856      0.025     -3.439      0.001      -0.134      -0.037\n",
       "zipcode_98112       1.9487      0.027     71.177      0.000       1.895       2.002\n",
       "zipcode_98003      -0.0824      0.026     -3.140      0.002      -0.134      -0.031\n",
       "zipcode_98115       1.5032      0.020     75.576      0.000       1.464       1.542\n",
       "zipcode_98117       1.4986      0.020     73.204      0.000       1.458       1.539\n",
       "zipcode_98103       1.5340      0.021     74.763      0.000       1.494       1.574\n",
       "zipcode_98105       1.7682      0.029     60.840      0.000       1.711       1.825\n",
       "grade_9            -0.1283      0.020     -6.403      0.000      -0.168      -0.089\n",
       "zipcode_98002      -0.1338      0.032     -4.153      0.000      -0.197      -0.071\n",
       "condition_3         0.6388      0.082      7.762      0.000       0.477       0.800\n",
       "zipcode_98119       1.8648      0.032     58.121      0.000       1.802       1.928\n",
       "zipcode_98032      -0.1259      0.039     -3.262      0.001      -0.202      -0.050\n",
       "zipcode_98039       2.4142      0.060     39.984      0.000       2.296       2.533\n",
       "zipcode_98040       1.5975      0.028     57.382      0.000       1.543       1.652\n",
       "zipcode_98199       1.6013      0.026     61.420      0.000       1.550       1.652\n",
       "zipcode_98033       1.3907      0.022     64.078      0.000       1.348       1.433\n",
       "zipcode_98107       1.6065      0.028     57.153      0.000       1.551       1.662\n",
       "zipcode_98122       1.5330      0.027     57.105      0.000       1.480       1.586\n",
       "zipcode_98116       1.4101      0.025     57.062      0.000       1.362       1.459\n",
       "zipcode_98109       1.8935      0.042     44.953      0.000       1.811       1.976\n",
       "zipcode_98102       1.7807      0.043     40.998      0.000       1.696       1.866\n",
       "sqft_lot_log        0.1174      0.004     28.380      0.000       0.109       0.126\n",
       "zipcode_98144       1.2436      0.025     49.520      0.000       1.194       1.293\n",
       "zipcode_98006       1.1488      0.022     52.888      0.000       1.106       1.191\n",
       "zipcode_98136       1.2739      0.028     45.631      0.000       1.219       1.329\n",
       "zipcode_98052       1.1050      0.020     55.397      0.000       1.066       1.144\n",
       "zipcode_98008       1.1704      0.026     44.783      0.000       1.119       1.222\n",
       "zipcode_98005       1.2484      0.033     37.316      0.000       1.183       1.314\n",
       "zipcode_98177       1.1294      0.027     42.037      0.000       1.077       1.182\n",
       "zipcode_98125       1.0070      0.022     44.981      0.000       0.963       1.051\n",
       "zipcode_98126       1.0065      0.024     41.124      0.000       0.959       1.054\n",
       "zipcode_98034       0.9540      0.020     47.407      0.000       0.915       0.993\n",
       "zipcode_98053       0.9862      0.023     43.026      0.000       0.941       1.031\n",
       "zipcode_98029       1.0372      0.025     40.783      0.000       0.987       1.087\n",
       "zipcode_98074       0.9354      0.023     41.543      0.000       0.891       0.980\n",
       "zipcode_98075       0.9579      0.024     39.609      0.000       0.911       1.005\n",
       "zipcode_98007       1.1308      0.037     30.818      0.000       1.059       1.203\n",
       "zipcode_98118       0.8590      0.021     40.731      0.000       0.818       0.900\n",
       "zipcode_98027       0.8441      0.023     37.403      0.000       0.800       0.888\n",
       "zipcode_98133       0.7843      0.021     37.110      0.000       0.743       0.826\n",
       "grade_10            0.0933      0.022      4.189      0.000       0.050       0.137\n",
       "grade_4            -0.8008      0.083     -9.594      0.000      -0.964      -0.637\n",
       "sale_month_4        0.1351      0.010     14.044      0.000       0.116       0.154\n",
       "condition_5         0.8383      0.083     10.126      0.000       0.676       1.001\n",
       "condition_4         0.7101      0.082      8.623      0.000       0.549       0.871\n",
       "zipcode_98072       0.7635      0.027     28.193      0.000       0.710       0.817\n",
       "zipcode_98065       0.7307      0.026     28.436      0.000       0.680       0.781\n",
       "zipcode_98155       0.7101      0.022     32.622      0.000       0.667       0.753\n",
       "zipcode_98011       0.7577      0.031     24.628      0.000       0.697       0.818\n",
       "zipcode_98028       0.6795      0.027     25.159      0.000       0.627       0.732\n",
       "sale_month_3        0.0964      0.010      9.278      0.000       0.076       0.117\n",
       "floors_2.0          0.0551      0.008      6.790      0.000       0.039       0.071\n",
       "grade_11            0.3640      0.027     13.240      0.000       0.310       0.418\n",
       "zipcode_98077       0.6496      0.032     20.396      0.000       0.587       0.712\n",
       "zipcode_98059       0.5519      0.022     25.459      0.000       0.509       0.594\n",
       "zipcode_98106       0.5633      0.025     22.759      0.000       0.515       0.612\n",
       "zipcode_98108       0.5754      0.033     17.580      0.000       0.511       0.640\n",
       "zipcode_98056       0.5073      0.023     22.460      0.000       0.463       0.552\n",
       "zipcode_98166       0.5114      0.028     18.419      0.000       0.457       0.566\n",
       "zipcode_98045       0.5179      0.030     17.037      0.000       0.458       0.577\n",
       "zipcode_98146       0.4475      0.026     17.111      0.000       0.396       0.499\n",
       "zipcode_98024       0.6519      0.047     13.874      0.000       0.560       0.744\n",
       "zipcode_98019       0.4818      0.032     15.201      0.000       0.420       0.544\n",
       "zipcode_98014       0.4444      0.039     11.472      0.000       0.368       0.520\n",
       "zipcode_98070       0.4063      0.041     10.006      0.000       0.327       0.486\n",
       "grade_12            0.6555      0.045     14.463      0.000       0.567       0.744\n",
       "grade_13            1.4022      0.134     10.487      0.000       1.140       1.664\n",
       "zipcode_98038       0.2216      0.020     11.350      0.000       0.183       0.260\n",
       "zipcode_98010       0.3245      0.043      7.464      0.000       0.239       0.410\n",
       "zipcode_98178       0.2248      0.028      8.037      0.000       0.170       0.280\n",
       "zipcode_98058       0.1855      0.021      8.675      0.000       0.144       0.227\n",
       "zipcode_98055       0.1632      0.027      5.967      0.000       0.110       0.217\n",
       "condition_2         0.4317      0.088      4.900      0.000       0.259       0.604\n",
       "floors_3.0         -0.0762      0.020     -3.776      0.000      -0.116      -0.037\n",
       "bedrooms_2          0.0449      0.010      4.481      0.000       0.025       0.065\n",
       "sale_month_2        0.0525      0.012      4.240      0.000       0.028       0.077\n",
       "zipcode_98148       0.2068      0.055      3.731      0.000       0.098       0.315\n",
       "sale_month_5        0.0318      0.009      3.439      0.001       0.014       0.050\n",
       "floors_1.5          0.0372      0.011      3.370      0.001       0.016       0.059\n",
       "bedrooms_7         -0.2228      0.066     -3.360      0.001      -0.353      -0.093\n",
       "==============================================================================\n",
       "Omnibus:                      878.545   Durbin-Watson:                   2.004\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3517.341\n",
       "Skew:                          -0.118   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.331   Cond. No.                     1.87e+15\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 9.02e-27. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X_fin = X_train[result]\n",
    "X_with_intercept = sm.add_constant(X_fin)\n",
    "model = sm.OLS(y_train,X_with_intercept).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False,  True, False,  True,  True,  True,\n",
       "        True,  True, False, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False, False,  True,  True,  True,\n",
       "        True, False, False, False,  True,  True, False,  True,  True,\n",
       "       False,  True,  True,  True, False,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True, False,  True, False, False, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linreg = LinearRegression()\n",
    "selector = RFE(linreg, n_features_to_select = 70)\n",
    "selector = selector.fit(X_train, y_train.values.ravel()) \n",
    "selector.support_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns = X_train.columns[selector.support_ ]\n",
    "linreg.fit(X_train[selected_columns],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sqft_living_log', 'bedrooms_9', 'floors_3.0', 'condition_2',\n",
       "       'condition_3', 'condition_4', 'condition_5', 'waterfront_1.0',\n",
       "       'zipcode_98004', 'zipcode_98005', 'zipcode_98006', 'zipcode_98007',\n",
       "       'zipcode_98008', 'zipcode_98010', 'zipcode_98011', 'zipcode_98014',\n",
       "       'zipcode_98019', 'zipcode_98024', 'zipcode_98027', 'zipcode_98028',\n",
       "       'zipcode_98029', 'zipcode_98033', 'zipcode_98034', 'zipcode_98039',\n",
       "       'zipcode_98040', 'zipcode_98045', 'zipcode_98052', 'zipcode_98053',\n",
       "       'zipcode_98056', 'zipcode_98059', 'zipcode_98065', 'zipcode_98070',\n",
       "       'zipcode_98072', 'zipcode_98074', 'zipcode_98075', 'zipcode_98077',\n",
       "       'zipcode_98102', 'zipcode_98103', 'zipcode_98105', 'zipcode_98106',\n",
       "       'zipcode_98107', 'zipcode_98108', 'zipcode_98109', 'zipcode_98112',\n",
       "       'zipcode_98115', 'zipcode_98116', 'zipcode_98117', 'zipcode_98118',\n",
       "       'zipcode_98119', 'zipcode_98122', 'zipcode_98125', 'zipcode_98126',\n",
       "       'zipcode_98133', 'zipcode_98136', 'zipcode_98144', 'zipcode_98146',\n",
       "       'zipcode_98155', 'zipcode_98166', 'zipcode_98177', 'zipcode_98199',\n",
       "       'grade_4', 'grade_5', 'grade_6', 'grade_7', 'grade_8', 'grade_9',\n",
       "       'grade_10', 'grade_11', 'grade_12', 'grade_13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = linreg.predict(X[selected_columns])\n",
    "y_hat_train = linreg.predict(X_train[selected_columns])\n",
    "y_hat_test = linreg.predict(X_test[selected_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS_Residual = np.sum((y-yhat)**2)\n",
    "SS_Total = np.sum((y-np.mean(y))**2)\n",
    "r_squared = 1 - (float(SS_Residual))/SS_Total\n",
    "adjusted_r_squared = 1 - (1-r_squared)*(len(y)-1)/(len(y)-X[selected_columns].shape[1]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.86574168253998e+17"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.901813864194605e+17"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Squarred Error: 0.13738302828596685\n",
      "Test Mean Squarred Error: 4.931587576222831e+18\n"
     ]
    }
   ],
   "source": [
    "mse_train = np.sum((y_train-y_hat_train)**2)/len(y_train)\n",
    "mse_test = np.sum((y_test-y_hat_test)**2)/len(y_test)\n",
    "print('Train Mean Squarred Error:', mse_train)\n",
    "print('Test Mean Squarred Error:', mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "# linreg = LinearRegression()\n",
    "\n",
    "# linreg.fit(X_train, y_train)\n",
    "# y_hat_test = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "# test_residuals = y_hat_test - y_test\n",
    "\n",
    "# test_mse = mean_squared_error(y_test, y_hat_test)\n",
    "# test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3706521661692629\n",
      "2220717806.526266\n"
     ]
    }
   ],
   "source": [
    "train_error_log = np.sqrt(mse_train)\n",
    "test_error_log = np.sqrt(mse_test)\n",
    "print(train_error_log)\n",
    "print(test_error_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 1.448679086143777\n",
      "test error: inf\n"
     ]
    }
   ],
   "source": [
    "train_error = np.exp(train_error_log)\n",
    "test_error = np.exp(test_error_log)\n",
    "print('train error:',train_error)\n",
    "print('test error:', test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sm.graphics.qqplot(model.resid, dist=stats.norm, line='45', fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(model.predict(y_hat_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>price_log</td>    <th>  R-squared (uncentered):</th>      <td>   0.868</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   360.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 24 Oct 2020</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:15:11</td>     <th>  Log-Likelihood:    </th>          <td> -1625.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  3844</td>      <th>  AIC:               </th>          <td>   3390.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  3775</td>      <th>  BIC:               </th>          <td>   3821.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    69</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_living_log</th> <td>    0.3917</td> <td>    0.010</td> <td>   40.650</td> <td> 0.000</td> <td>    0.373</td> <td>    0.411</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bedrooms_9</th>      <td> -2.33e-16</td> <td>  6.6e-16</td> <td>   -0.353</td> <td> 0.724</td> <td>-1.53e-15</td> <td> 1.06e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>floors_3.0</th>      <td>   -0.2041</td> <td>    0.038</td> <td>   -5.414</td> <td> 0.000</td> <td>   -0.278</td> <td>   -0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition_2</th>     <td>   -0.6492</td> <td>    0.157</td> <td>   -4.126</td> <td> 0.000</td> <td>   -0.958</td> <td>   -0.341</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition_3</th>     <td>   -0.2673</td> <td>    0.144</td> <td>   -1.855</td> <td> 0.064</td> <td>   -0.550</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition_4</th>     <td>   -0.1887</td> <td>    0.144</td> <td>   -1.308</td> <td> 0.191</td> <td>   -0.471</td> <td>    0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition_5</th>     <td>   -0.0700</td> <td>    0.145</td> <td>   -0.483</td> <td> 0.629</td> <td>   -0.354</td> <td>    0.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>waterfront_1.0</th>  <td>    1.2851</td> <td>    0.072</td> <td>   17.740</td> <td> 0.000</td> <td>    1.143</td> <td>    1.427</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98004</th>   <td>    1.9901</td> <td>    0.047</td> <td>   42.580</td> <td> 0.000</td> <td>    1.898</td> <td>    2.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98005</th>   <td>    1.3270</td> <td>    0.065</td> <td>   20.421</td> <td> 0.000</td> <td>    1.200</td> <td>    1.454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98006</th>   <td>    1.1401</td> <td>    0.041</td> <td>   27.505</td> <td> 0.000</td> <td>    1.059</td> <td>    1.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98007</th>   <td>    1.0648</td> <td>    0.082</td> <td>   12.920</td> <td> 0.000</td> <td>    0.903</td> <td>    1.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98008</th>   <td>    1.1258</td> <td>    0.057</td> <td>   19.729</td> <td> 0.000</td> <td>    1.014</td> <td>    1.238</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98010</th>   <td>    0.2896</td> <td>    0.091</td> <td>    3.172</td> <td> 0.002</td> <td>    0.111</td> <td>    0.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98011</th>   <td>    0.6726</td> <td>    0.069</td> <td>    9.721</td> <td> 0.000</td> <td>    0.537</td> <td>    0.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98014</th>   <td>    0.3412</td> <td>    0.087</td> <td>    3.940</td> <td> 0.000</td> <td>    0.171</td> <td>    0.511</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98019</th>   <td>    0.5810</td> <td>    0.069</td> <td>    8.393</td> <td> 0.000</td> <td>    0.445</td> <td>    0.717</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98024</th>   <td>    0.8384</td> <td>    0.105</td> <td>    7.980</td> <td> 0.000</td> <td>    0.632</td> <td>    1.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98027</th>   <td>    0.8296</td> <td>    0.045</td> <td>   18.579</td> <td> 0.000</td> <td>    0.742</td> <td>    0.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98028</th>   <td>    0.6632</td> <td>    0.049</td> <td>   13.579</td> <td> 0.000</td> <td>    0.567</td> <td>    0.759</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98029</th>   <td>    0.9481</td> <td>    0.049</td> <td>   19.163</td> <td> 0.000</td> <td>    0.851</td> <td>    1.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98033</th>   <td>    1.3799</td> <td>    0.054</td> <td>   25.690</td> <td> 0.000</td> <td>    1.275</td> <td>    1.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98034</th>   <td>    0.9127</td> <td>    0.040</td> <td>   22.965</td> <td> 0.000</td> <td>    0.835</td> <td>    0.991</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98039</th>   <td>    2.3716</td> <td>    0.126</td> <td>   18.768</td> <td> 0.000</td> <td>    2.124</td> <td>    2.619</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98040</th>   <td>    1.6142</td> <td>    0.053</td> <td>   30.646</td> <td> 0.000</td> <td>    1.511</td> <td>    1.717</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98045</th>   <td>    0.5084</td> <td>    0.061</td> <td>    8.333</td> <td> 0.000</td> <td>    0.389</td> <td>    0.628</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98052</th>   <td>    1.0312</td> <td>    0.039</td> <td>   26.460</td> <td> 0.000</td> <td>    0.955</td> <td>    1.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98053</th>   <td>    1.1047</td> <td>    0.046</td> <td>   23.923</td> <td> 0.000</td> <td>    1.014</td> <td>    1.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98056</th>   <td>    0.4642</td> <td>    0.046</td> <td>   10.112</td> <td> 0.000</td> <td>    0.374</td> <td>    0.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98059</th>   <td>    0.5422</td> <td>    0.043</td> <td>   12.647</td> <td> 0.000</td> <td>    0.458</td> <td>    0.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98065</th>   <td>    0.6709</td> <td>    0.051</td> <td>   13.222</td> <td> 0.000</td> <td>    0.571</td> <td>    0.770</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98070</th>   <td>    0.6783</td> <td>    0.083</td> <td>    8.182</td> <td> 0.000</td> <td>    0.516</td> <td>    0.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98072</th>   <td>    0.8301</td> <td>    0.055</td> <td>   15.136</td> <td> 0.000</td> <td>    0.723</td> <td>    0.938</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98074</th>   <td>    0.8779</td> <td>    0.045</td> <td>   19.331</td> <td> 0.000</td> <td>    0.789</td> <td>    0.967</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98075</th>   <td>    0.9988</td> <td>    0.050</td> <td>   20.129</td> <td> 0.000</td> <td>    0.902</td> <td>    1.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98077</th>   <td>    0.8522</td> <td>    0.065</td> <td>   13.179</td> <td> 0.000</td> <td>    0.725</td> <td>    0.979</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98102</th>   <td>    1.6122</td> <td>    0.092</td> <td>   17.604</td> <td> 0.000</td> <td>    1.433</td> <td>    1.792</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98103</th>   <td>    1.4551</td> <td>    0.039</td> <td>   36.905</td> <td> 0.000</td> <td>    1.378</td> <td>    1.532</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98105</th>   <td>    1.6259</td> <td>    0.061</td> <td>   26.634</td> <td> 0.000</td> <td>    1.506</td> <td>    1.746</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98106</th>   <td>    0.4712</td> <td>    0.052</td> <td>    9.090</td> <td> 0.000</td> <td>    0.370</td> <td>    0.573</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98107</th>   <td>    1.4436</td> <td>    0.056</td> <td>   25.686</td> <td> 0.000</td> <td>    1.333</td> <td>    1.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98108</th>   <td>    0.5891</td> <td>    0.062</td> <td>    9.549</td> <td> 0.000</td> <td>    0.468</td> <td>    0.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98109</th>   <td>    1.6845</td> <td>    0.084</td> <td>   19.972</td> <td> 0.000</td> <td>    1.519</td> <td>    1.850</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98112</th>   <td>    1.8656</td> <td>    0.056</td> <td>   33.127</td> <td> 0.000</td> <td>    1.755</td> <td>    1.976</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98115</th>   <td>    1.3754</td> <td>    0.040</td> <td>   34.038</td> <td> 0.000</td> <td>    1.296</td> <td>    1.455</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98116</th>   <td>    1.3711</td> <td>    0.054</td> <td>   25.606</td> <td> 0.000</td> <td>    1.266</td> <td>    1.476</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98117</th>   <td>    1.3467</td> <td>    0.040</td> <td>   33.817</td> <td> 0.000</td> <td>    1.269</td> <td>    1.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98118</th>   <td>    0.6791</td> <td>    0.041</td> <td>   16.427</td> <td> 0.000</td> <td>    0.598</td> <td>    0.760</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98119</th>   <td>    1.7103</td> <td>    0.073</td> <td>   23.369</td> <td> 0.000</td> <td>    1.567</td> <td>    1.854</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98122</th>   <td>    1.2712</td> <td>    0.053</td> <td>   23.926</td> <td> 0.000</td> <td>    1.167</td> <td>    1.375</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98125</th>   <td>    0.9114</td> <td>    0.049</td> <td>   18.645</td> <td> 0.000</td> <td>    0.816</td> <td>    1.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98126</th>   <td>    0.8322</td> <td>    0.049</td> <td>   16.971</td> <td> 0.000</td> <td>    0.736</td> <td>    0.928</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98133</th>   <td>    0.7065</td> <td>    0.044</td> <td>   16.199</td> <td> 0.000</td> <td>    0.621</td> <td>    0.792</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98136</th>   <td>    1.2056</td> <td>    0.053</td> <td>   22.665</td> <td> 0.000</td> <td>    1.101</td> <td>    1.310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98144</th>   <td>    1.1317</td> <td>    0.049</td> <td>   23.101</td> <td> 0.000</td> <td>    1.036</td> <td>    1.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98146</th>   <td>    0.3369</td> <td>    0.055</td> <td>    6.154</td> <td> 0.000</td> <td>    0.230</td> <td>    0.444</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98155</th>   <td>    0.6698</td> <td>    0.043</td> <td>   15.398</td> <td> 0.000</td> <td>    0.584</td> <td>    0.755</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98166</th>   <td>    0.4034</td> <td>    0.063</td> <td>    6.357</td> <td> 0.000</td> <td>    0.279</td> <td>    0.528</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98177</th>   <td>    0.9944</td> <td>    0.064</td> <td>   15.607</td> <td> 0.000</td> <td>    0.870</td> <td>    1.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98199</th>   <td>    1.4303</td> <td>    0.051</td> <td>   28.208</td> <td> 0.000</td> <td>    1.331</td> <td>    1.530</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_4</th>         <td>   -0.8546</td> <td>    0.180</td> <td>   -4.748</td> <td> 0.000</td> <td>   -1.208</td> <td>   -0.502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_5</th>         <td>   -0.9289</td> <td>    0.154</td> <td>   -6.041</td> <td> 0.000</td> <td>   -1.230</td> <td>   -0.627</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_6</th>         <td>   -0.8095</td> <td>    0.145</td> <td>   -5.595</td> <td> 0.000</td> <td>   -1.093</td> <td>   -0.526</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_7</th>         <td>   -0.7197</td> <td>    0.144</td> <td>   -4.989</td> <td> 0.000</td> <td>   -1.002</td> <td>   -0.437</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_8</th>         <td>   -0.4997</td> <td>    0.145</td> <td>   -3.444</td> <td> 0.001</td> <td>   -0.784</td> <td>   -0.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_9</th>         <td>   -0.1820</td> <td>    0.146</td> <td>   -1.244</td> <td> 0.213</td> <td>   -0.469</td> <td>    0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_10</th>        <td>    0.0318</td> <td>    0.149</td> <td>    0.214</td> <td> 0.831</td> <td>   -0.260</td> <td>    0.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_11</th>        <td>    0.3522</td> <td>    0.154</td> <td>    2.286</td> <td> 0.022</td> <td>    0.050</td> <td>    0.654</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_12</th>        <td>    0.8314</td> <td>    0.174</td> <td>    4.775</td> <td> 0.000</td> <td>    0.490</td> <td>    1.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_13</th>        <td>    1.2859</td> <td>    0.208</td> <td>    6.172</td> <td> 0.000</td> <td>    0.877</td> <td>    1.694</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>232.929</td> <th>  Durbin-Watson:     </th> <td>   2.017</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 971.323</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.107</td>  <th>  Prob(JB):          </th> <td>1.20e-211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.453</td>  <th>  Cond. No.          </th> <td>2.25e+15</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 8.3e-28. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:              price_log   R-squared (uncentered):                   0.868\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.866\n",
       "Method:                 Least Squares   F-statistic:                              360.5\n",
       "Date:                Sat, 24 Oct 2020   Prob (F-statistic):                        0.00\n",
       "Time:                        11:15:11   Log-Likelihood:                         -1625.8\n",
       "No. Observations:                3844   AIC:                                      3390.\n",
       "Df Residuals:                    3775   BIC:                                      3821.\n",
       "Df Model:                          69                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "sqft_living_log     0.3917      0.010     40.650      0.000       0.373       0.411\n",
       "bedrooms_9       -2.33e-16    6.6e-16     -0.353      0.724   -1.53e-15    1.06e-15\n",
       "floors_3.0         -0.2041      0.038     -5.414      0.000      -0.278      -0.130\n",
       "condition_2        -0.6492      0.157     -4.126      0.000      -0.958      -0.341\n",
       "condition_3        -0.2673      0.144     -1.855      0.064      -0.550       0.015\n",
       "condition_4        -0.1887      0.144     -1.308      0.191      -0.471       0.094\n",
       "condition_5        -0.0700      0.145     -0.483      0.629      -0.354       0.214\n",
       "waterfront_1.0      1.2851      0.072     17.740      0.000       1.143       1.427\n",
       "zipcode_98004       1.9901      0.047     42.580      0.000       1.898       2.082\n",
       "zipcode_98005       1.3270      0.065     20.421      0.000       1.200       1.454\n",
       "zipcode_98006       1.1401      0.041     27.505      0.000       1.059       1.221\n",
       "zipcode_98007       1.0648      0.082     12.920      0.000       0.903       1.226\n",
       "zipcode_98008       1.1258      0.057     19.729      0.000       1.014       1.238\n",
       "zipcode_98010       0.2896      0.091      3.172      0.002       0.111       0.469\n",
       "zipcode_98011       0.6726      0.069      9.721      0.000       0.537       0.808\n",
       "zipcode_98014       0.3412      0.087      3.940      0.000       0.171       0.511\n",
       "zipcode_98019       0.5810      0.069      8.393      0.000       0.445       0.717\n",
       "zipcode_98024       0.8384      0.105      7.980      0.000       0.632       1.044\n",
       "zipcode_98027       0.8296      0.045     18.579      0.000       0.742       0.917\n",
       "zipcode_98028       0.6632      0.049     13.579      0.000       0.567       0.759\n",
       "zipcode_98029       0.9481      0.049     19.163      0.000       0.851       1.045\n",
       "zipcode_98033       1.3799      0.054     25.690      0.000       1.275       1.485\n",
       "zipcode_98034       0.9127      0.040     22.965      0.000       0.835       0.991\n",
       "zipcode_98039       2.3716      0.126     18.768      0.000       2.124       2.619\n",
       "zipcode_98040       1.6142      0.053     30.646      0.000       1.511       1.717\n",
       "zipcode_98045       0.5084      0.061      8.333      0.000       0.389       0.628\n",
       "zipcode_98052       1.0312      0.039     26.460      0.000       0.955       1.108\n",
       "zipcode_98053       1.1047      0.046     23.923      0.000       1.014       1.195\n",
       "zipcode_98056       0.4642      0.046     10.112      0.000       0.374       0.554\n",
       "zipcode_98059       0.5422      0.043     12.647      0.000       0.458       0.626\n",
       "zipcode_98065       0.6709      0.051     13.222      0.000       0.571       0.770\n",
       "zipcode_98070       0.6783      0.083      8.182      0.000       0.516       0.841\n",
       "zipcode_98072       0.8301      0.055     15.136      0.000       0.723       0.938\n",
       "zipcode_98074       0.8779      0.045     19.331      0.000       0.789       0.967\n",
       "zipcode_98075       0.9988      0.050     20.129      0.000       0.902       1.096\n",
       "zipcode_98077       0.8522      0.065     13.179      0.000       0.725       0.979\n",
       "zipcode_98102       1.6122      0.092     17.604      0.000       1.433       1.792\n",
       "zipcode_98103       1.4551      0.039     36.905      0.000       1.378       1.532\n",
       "zipcode_98105       1.6259      0.061     26.634      0.000       1.506       1.746\n",
       "zipcode_98106       0.4712      0.052      9.090      0.000       0.370       0.573\n",
       "zipcode_98107       1.4436      0.056     25.686      0.000       1.333       1.554\n",
       "zipcode_98108       0.5891      0.062      9.549      0.000       0.468       0.710\n",
       "zipcode_98109       1.6845      0.084     19.972      0.000       1.519       1.850\n",
       "zipcode_98112       1.8656      0.056     33.127      0.000       1.755       1.976\n",
       "zipcode_98115       1.3754      0.040     34.038      0.000       1.296       1.455\n",
       "zipcode_98116       1.3711      0.054     25.606      0.000       1.266       1.476\n",
       "zipcode_98117       1.3467      0.040     33.817      0.000       1.269       1.425\n",
       "zipcode_98118       0.6791      0.041     16.427      0.000       0.598       0.760\n",
       "zipcode_98119       1.7103      0.073     23.369      0.000       1.567       1.854\n",
       "zipcode_98122       1.2712      0.053     23.926      0.000       1.167       1.375\n",
       "zipcode_98125       0.9114      0.049     18.645      0.000       0.816       1.007\n",
       "zipcode_98126       0.8322      0.049     16.971      0.000       0.736       0.928\n",
       "zipcode_98133       0.7065      0.044     16.199      0.000       0.621       0.792\n",
       "zipcode_98136       1.2056      0.053     22.665      0.000       1.101       1.310\n",
       "zipcode_98144       1.1317      0.049     23.101      0.000       1.036       1.228\n",
       "zipcode_98146       0.3369      0.055      6.154      0.000       0.230       0.444\n",
       "zipcode_98155       0.6698      0.043     15.398      0.000       0.584       0.755\n",
       "zipcode_98166       0.4034      0.063      6.357      0.000       0.279       0.528\n",
       "zipcode_98177       0.9944      0.064     15.607      0.000       0.870       1.119\n",
       "zipcode_98199       1.4303      0.051     28.208      0.000       1.331       1.530\n",
       "grade_4            -0.8546      0.180     -4.748      0.000      -1.208      -0.502\n",
       "grade_5            -0.9289      0.154     -6.041      0.000      -1.230      -0.627\n",
       "grade_6            -0.8095      0.145     -5.595      0.000      -1.093      -0.526\n",
       "grade_7            -0.7197      0.144     -4.989      0.000      -1.002      -0.437\n",
       "grade_8            -0.4997      0.145     -3.444      0.001      -0.784      -0.215\n",
       "grade_9            -0.1820      0.146     -1.244      0.213      -0.469       0.105\n",
       "grade_10            0.0318      0.149      0.214      0.831      -0.260       0.323\n",
       "grade_11            0.3522      0.154      2.286      0.022       0.050       0.654\n",
       "grade_12            0.8314      0.174      4.775      0.000       0.490       1.173\n",
       "grade_13            1.2859      0.208      6.172      0.000       0.877       1.694\n",
       "==============================================================================\n",
       "Omnibus:                      232.929   Durbin-Watson:                   2.017\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              971.323\n",
       "Skew:                           0.107   Prob(JB):                    1.20e-211\n",
       "Kurtosis:                       5.453   Cond. No.                     2.25e+15\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 8.3e-28. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.OLS(y_test,X_test[selected_columns]).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = sm.graphics.qqplot(model.resid, dist=stats.norm, line='45', fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
